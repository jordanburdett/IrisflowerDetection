{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LearningKeras.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPPqGjrT13tNLx/mlBKPUfK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jordanburdett/IrisflowerDetection/blob/master/LearningKeras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuNecKy15TA5",
        "colab_type": "code",
        "outputId": "b4ccc5cd-c2dd-479a-9759-4b40b7eae092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i608JrAU5d0g",
        "colab_type": "text"
      },
      "source": [
        "The first dataset that I will be using to learn Keras. The goal is to predict if a car is acceptable based off of 6 features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVLay5lp5L_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "names = [\"price\", \"maint\", \"doors\", \"numPeople\", \"cargoSpace\", \"safteyMeasure\", \"acceptable\"]\n",
        "carData = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\", header=None, skipinitialspace=True, names=names, na_values=[\"?\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtCHo6KI5eAQ",
        "colab_type": "text"
      },
      "source": [
        "First we need to get rid of all the string data and tokenize it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wvx_T1Q_Dvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def makeCatCodes(data):\n",
        "  for label,dtype in data.dtypes.items():\n",
        "    if dtype == object:\n",
        "        print(label)\n",
        "        # set the dataframe to be a category\n",
        "        data[label] = data[label].astype('category')\n",
        "\n",
        "        # create new row using cat codes\n",
        "        data[\"{}_cat\".format(label)] = data[label].cat.codes\n",
        "        \n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KevMsvQJ-y12",
        "colab_type": "code",
        "outputId": "17e806e3-3815-4a7c-ab96-19ace4e278ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "carData = makeCatCodes(carData)\n",
        "\n",
        "features = carData[['price_cat', 'maint_cat', 'doors_cat', 'numPeople_cat', 'cargoSpace_cat', 'safteyMeasure_cat']].to_numpy()\n",
        "targets = carData['acceptable_cat'].to_numpy()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "price\n",
            "maint\n",
            "doors\n",
            "numPeople\n",
            "cargoSpace\n",
            "safteyMeasure\n",
            "acceptable\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IolYMxc3KfV2",
        "colab_type": "code",
        "outputId": "41dda1bb-abc0-4d5b-bc1a-92528ec2e29d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "targets[:5]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, 2, 2], dtype=int8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfKPTpnw9aCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, test_data, train_targets, test_targets = train_test_split(features, targets, test_size=.3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1erMW9aLYPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(200, activation='relu', input_dim=6))\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iox-LS1kNYDe",
        "colab_type": "code",
        "outputId": "94078ef3-97ad-4908-8fba-56c6b32d4775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_data, train_targets, epochs=100)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1209/1209 [==============================] - 2s 1ms/step - loss: 0.8908 - accuracy: 0.6485\n",
            "Epoch 2/100\n",
            "1209/1209 [==============================] - 0s 77us/step - loss: 0.7126 - accuracy: 0.7055\n",
            "Epoch 3/100\n",
            "1209/1209 [==============================] - 0s 74us/step - loss: 0.6542 - accuracy: 0.7072\n",
            "Epoch 4/100\n",
            "1209/1209 [==============================] - 0s 71us/step - loss: 0.6021 - accuracy: 0.7328\n",
            "Epoch 5/100\n",
            "1209/1209 [==============================] - 0s 80us/step - loss: 0.5498 - accuracy: 0.7577\n",
            "Epoch 6/100\n",
            "1209/1209 [==============================] - 0s 77us/step - loss: 0.4879 - accuracy: 0.8031\n",
            "Epoch 7/100\n",
            "1209/1209 [==============================] - 0s 73us/step - loss: 0.4324 - accuracy: 0.8180\n",
            "Epoch 8/100\n",
            "1209/1209 [==============================] - 0s 74us/step - loss: 0.3857 - accuracy: 0.8371\n",
            "Epoch 9/100\n",
            "1209/1209 [==============================] - 0s 71us/step - loss: 0.3485 - accuracy: 0.8470\n",
            "Epoch 10/100\n",
            "1209/1209 [==============================] - 0s 70us/step - loss: 0.3072 - accuracy: 0.8768\n",
            "Epoch 11/100\n",
            "1209/1209 [==============================] - 0s 83us/step - loss: 0.2873 - accuracy: 0.8867\n",
            "Epoch 12/100\n",
            "1209/1209 [==============================] - 0s 73us/step - loss: 0.2652 - accuracy: 0.9065\n",
            "Epoch 13/100\n",
            "1209/1209 [==============================] - 0s 74us/step - loss: 0.2452 - accuracy: 0.9057\n",
            "Epoch 14/100\n",
            "1209/1209 [==============================] - 0s 80us/step - loss: 0.2268 - accuracy: 0.9214\n",
            "Epoch 15/100\n",
            "1209/1209 [==============================] - 0s 98us/step - loss: 0.2116 - accuracy: 0.9247\n",
            "Epoch 16/100\n",
            "1209/1209 [==============================] - 0s 97us/step - loss: 0.2008 - accuracy: 0.9289\n",
            "Epoch 17/100\n",
            "1209/1209 [==============================] - 0s 95us/step - loss: 0.1953 - accuracy: 0.9305\n",
            "Epoch 18/100\n",
            "1209/1209 [==============================] - 0s 98us/step - loss: 0.1921 - accuracy: 0.9239\n",
            "Epoch 19/100\n",
            "1209/1209 [==============================] - 0s 82us/step - loss: 0.1687 - accuracy: 0.9413\n",
            "Epoch 20/100\n",
            "1209/1209 [==============================] - 0s 74us/step - loss: 0.1537 - accuracy: 0.9504\n",
            "Epoch 21/100\n",
            "1209/1209 [==============================] - 0s 72us/step - loss: 0.1459 - accuracy: 0.9570\n",
            "Epoch 22/100\n",
            "1209/1209 [==============================] - 0s 71us/step - loss: 0.1481 - accuracy: 0.9429\n",
            "Epoch 23/100\n",
            "1209/1209 [==============================] - 0s 80us/step - loss: 0.1265 - accuracy: 0.9677\n",
            "Epoch 24/100\n",
            "1209/1209 [==============================] - 0s 73us/step - loss: 0.1266 - accuracy: 0.9620\n",
            "Epoch 25/100\n",
            "1209/1209 [==============================] - 0s 81us/step - loss: 0.1166 - accuracy: 0.9653\n",
            "Epoch 26/100\n",
            "1209/1209 [==============================] - 0s 82us/step - loss: 0.1118 - accuracy: 0.9644\n",
            "Epoch 27/100\n",
            "1209/1209 [==============================] - 0s 71us/step - loss: 0.1037 - accuracy: 0.9702\n",
            "Epoch 28/100\n",
            "1209/1209 [==============================] - 0s 72us/step - loss: 0.1177 - accuracy: 0.9653\n",
            "Epoch 29/100\n",
            "1209/1209 [==============================] - 0s 75us/step - loss: 0.0982 - accuracy: 0.9735\n",
            "Epoch 30/100\n",
            "1209/1209 [==============================] - 0s 72us/step - loss: 0.0989 - accuracy: 0.9702\n",
            "Epoch 31/100\n",
            "1209/1209 [==============================] - 0s 72us/step - loss: 0.0884 - accuracy: 0.9793\n",
            "Epoch 32/100\n",
            "1209/1209 [==============================] - 0s 74us/step - loss: 0.0851 - accuracy: 0.9760\n",
            "Epoch 33/100\n",
            "1209/1209 [==============================] - 0s 71us/step - loss: 0.0761 - accuracy: 0.9826\n",
            "Epoch 34/100\n",
            "1209/1209 [==============================] - 0s 77us/step - loss: 0.0709 - accuracy: 0.9859\n",
            "Epoch 35/100\n",
            "1209/1209 [==============================] - 0s 72us/step - loss: 0.0667 - accuracy: 0.9868\n",
            "Epoch 36/100\n",
            "1209/1209 [==============================] - 0s 72us/step - loss: 0.0665 - accuracy: 0.9859\n",
            "Epoch 37/100\n",
            "1209/1209 [==============================] - 0s 82us/step - loss: 0.0638 - accuracy: 0.9868\n",
            "Epoch 38/100\n",
            "1209/1209 [==============================] - 0s 80us/step - loss: 0.0632 - accuracy: 0.9868\n",
            "Epoch 39/100\n",
            "1209/1209 [==============================] - 0s 74us/step - loss: 0.0563 - accuracy: 0.9892\n",
            "Epoch 40/100\n",
            "1209/1209 [==============================] - 0s 75us/step - loss: 0.0550 - accuracy: 0.9901\n",
            "Epoch 41/100\n",
            "1209/1209 [==============================] - 0s 72us/step - loss: 0.0562 - accuracy: 0.9859\n",
            "Epoch 42/100\n",
            "1209/1209 [==============================] - 0s 75us/step - loss: 0.0540 - accuracy: 0.9901\n",
            "Epoch 43/100\n",
            "1209/1209 [==============================] - 0s 69us/step - loss: 0.0529 - accuracy: 0.9868\n",
            "Epoch 44/100\n",
            "1209/1209 [==============================] - 0s 74us/step - loss: 0.0542 - accuracy: 0.9851\n",
            "Epoch 45/100\n",
            "1209/1209 [==============================] - 0s 72us/step - loss: 0.0571 - accuracy: 0.9851\n",
            "Epoch 46/100\n",
            "1209/1209 [==============================] - 0s 72us/step - loss: 0.0439 - accuracy: 0.9942\n",
            "Epoch 47/100\n",
            "1209/1209 [==============================] - 0s 75us/step - loss: 0.0397 - accuracy: 0.9934\n",
            "Epoch 48/100\n",
            "1209/1209 [==============================] - 0s 81us/step - loss: 0.0392 - accuracy: 0.9959\n",
            "Epoch 49/100\n",
            "1209/1209 [==============================] - 0s 73us/step - loss: 0.0458 - accuracy: 0.9892\n",
            "Epoch 50/100\n",
            "1209/1209 [==============================] - 0s 76us/step - loss: 0.0347 - accuracy: 0.9950\n",
            "Epoch 51/100\n",
            "1209/1209 [==============================] - 0s 68us/step - loss: 0.0329 - accuracy: 0.9975\n",
            "Epoch 52/100\n",
            "1209/1209 [==============================] - 0s 74us/step - loss: 0.0294 - accuracy: 0.9992\n",
            "Epoch 53/100\n",
            "1209/1209 [==============================] - 0s 71us/step - loss: 0.0319 - accuracy: 0.9967\n",
            "Epoch 54/100\n",
            "1209/1209 [==============================] - 0s 73us/step - loss: 0.0313 - accuracy: 0.9950\n",
            "Epoch 55/100\n",
            "1209/1209 [==============================] - 0s 73us/step - loss: 0.0326 - accuracy: 0.9942\n",
            "Epoch 56/100\n",
            "1209/1209 [==============================] - 0s 75us/step - loss: 0.0277 - accuracy: 0.9959\n",
            "Epoch 57/100\n",
            "1209/1209 [==============================] - 0s 71us/step - loss: 0.0248 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "1209/1209 [==============================] - 0s 77us/step - loss: 0.0258 - accuracy: 0.9975\n",
            "Epoch 59/100\n",
            "1209/1209 [==============================] - 0s 84us/step - loss: 0.0246 - accuracy: 0.9992\n",
            "Epoch 60/100\n",
            "1209/1209 [==============================] - 0s 74us/step - loss: 0.0266 - accuracy: 0.9967\n",
            "Epoch 61/100\n",
            "1209/1209 [==============================] - 0s 74us/step - loss: 0.0253 - accuracy: 0.9967\n",
            "Epoch 62/100\n",
            "1209/1209 [==============================] - 0s 73us/step - loss: 0.0222 - accuracy: 0.9983\n",
            "Epoch 63/100\n",
            "1209/1209 [==============================] - 0s 73us/step - loss: 0.0210 - accuracy: 0.9983\n",
            "Epoch 64/100\n",
            "1209/1209 [==============================] - 0s 86us/step - loss: 0.0242 - accuracy: 0.9967\n",
            "Epoch 65/100\n",
            "1209/1209 [==============================] - 0s 76us/step - loss: 0.0191 - accuracy: 0.9983\n",
            "Epoch 66/100\n",
            "1209/1209 [==============================] - 0s 75us/step - loss: 0.0161 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "1209/1209 [==============================] - 0s 74us/step - loss: 0.0153 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "1209/1209 [==============================] - 0s 79us/step - loss: 0.0138 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "1209/1209 [==============================] - 0s 75us/step - loss: 0.0149 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "1209/1209 [==============================] - 0s 85us/step - loss: 0.0192 - accuracy: 0.9975\n",
            "Epoch 71/100\n",
            "1209/1209 [==============================] - 0s 80us/step - loss: 0.0162 - accuracy: 0.9983\n",
            "Epoch 72/100\n",
            "1209/1209 [==============================] - 0s 73us/step - loss: 0.0131 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "1209/1209 [==============================] - 0s 76us/step - loss: 0.0121 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "1209/1209 [==============================] - 0s 73us/step - loss: 0.0125 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "1209/1209 [==============================] - 0s 73us/step - loss: 0.0147 - accuracy: 0.9983\n",
            "Epoch 76/100\n",
            "1209/1209 [==============================] - 0s 78us/step - loss: 0.0149 - accuracy: 0.9983\n",
            "Epoch 77/100\n",
            "1209/1209 [==============================] - 0s 75us/step - loss: 0.0207 - accuracy: 0.9942\n",
            "Epoch 78/100\n",
            "1209/1209 [==============================] - 0s 79us/step - loss: 0.0130 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "1209/1209 [==============================] - 0s 73us/step - loss: 0.0115 - accuracy: 0.9992\n",
            "Epoch 80/100\n",
            "1209/1209 [==============================] - 0s 83us/step - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "1209/1209 [==============================] - 0s 84us/step - loss: 0.0085 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "1209/1209 [==============================] - 0s 73us/step - loss: 0.0081 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "1209/1209 [==============================] - 0s 75us/step - loss: 0.0086 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "1209/1209 [==============================] - 0s 71us/step - loss: 0.0086 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "1209/1209 [==============================] - 0s 76us/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "1209/1209 [==============================] - 0s 75us/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "1209/1209 [==============================] - 0s 86us/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "1209/1209 [==============================] - 0s 77us/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "1209/1209 [==============================] - 0s 78us/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "1209/1209 [==============================] - 0s 81us/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "1209/1209 [==============================] - 0s 87us/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "1209/1209 [==============================] - 0s 76us/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "1209/1209 [==============================] - 0s 82us/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "1209/1209 [==============================] - 0s 73us/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "1209/1209 [==============================] - 0s 73us/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "1209/1209 [==============================] - 0s 72us/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "1209/1209 [==============================] - 0s 74us/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "1209/1209 [==============================] - 0s 73us/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "1209/1209 [==============================] - 0s 74us/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "1209/1209 [==============================] - 0s 75us/step - loss: 0.0040 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f83ba3019e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4fItfZJNk7M",
        "colab_type": "code",
        "outputId": "5b54e297-4d42-4a26-e33f-4b33a7c130b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "model.predict(test_data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.5167977e-18, 4.1396564e-29, 1.0000000e+00, 7.6271360e-36],\n",
              "       [9.5703979e-11, 3.4578725e-16, 1.0000000e+00, 2.3205919e-25],\n",
              "       [9.9684441e-01, 1.7837763e-05, 1.3789864e-06, 3.1363762e-03],\n",
              "       ...,\n",
              "       [8.5954893e-01, 5.7189723e-06, 1.4044529e-01, 9.9941656e-17],\n",
              "       [9.8058689e-01, 6.8030239e-12, 1.9413074e-02, 2.1404411e-24],\n",
              "       [1.2322470e-15, 2.1437904e-33, 1.0000000e+00, 0.0000000e+00]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR76Rr-uRp8L",
        "colab_type": "code",
        "outputId": "890ec817-5042-4c3a-e1e5-d9a45548808f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "pred_train = model.predict(train_data)\n",
        "scores = model.evaluate(train_data, train_targets, verbose=0)\n",
        "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   \n",
        " \n",
        "pred_test = model.predict(test_data)\n",
        "scores2 = model.evaluate(test_data, test_targets, verbose=0)\n",
        "print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training data: 1.0% \n",
            " Error on training data: 0.0\n",
            "Accuracy on test data: 0.9903661012649536% \n",
            " Error on test data: 0.009633898735046387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ytp4VZAKbPV5",
        "colab_type": "text"
      },
      "source": [
        "The first attempt at using the model was very successful getting around 97% accuracy each time. Tweaking some of the parameters I was able to get it up to 99%. The biggest mistake I had with this model was when I categorized the data the features had a value of either 1,2,3,4 which made it so I had to allow for 4 outpus rather than 3. Once I pre processed the data a little better I was able to get better accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHknLCECNwtl",
        "colab_type": "text"
      },
      "source": [
        "The second dataset that I will be doing for this project is using census data to determine if someone makes more that 50,000 dollars a year."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "up83nzY8NxxQ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GolM7-u-NueS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "headers = [\"age\", \"workType\", \"id\", \"education\", \"educationNumber\", \"maritalStatus\", \"occupation\", \"relationship\", \"race\", \"sex\", \"gain\", \"loss\", \"hoursPerWeek\", \"country\", \"income\"]\n",
        "censusTrainData = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", names=headers, na_values='?')\n",
        "\n",
        "censusTestData = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\", names=headers, na_values=\"?\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmcSD-3rOYDR",
        "colab_type": "code",
        "outputId": "cfcea209-ca94-4fa7-a578-3af3d884633b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "censusTrainData = makeCatCodes(censusTrainData)\n",
        "\n",
        "trainData = censusTrainData[['age', 'workType_cat', 'educationNumber', 'maritalStatus_cat', 'occupation_cat', 'relationship_cat', 'race_cat', 'sex_cat', 'gain', 'loss', 'hoursPerWeek', 'country_cat']]\n",
        "trainTargets = censusTrainData['income_cat']\n",
        "\n",
        "censusTestData = makeCatCodes(censusTestData)\n",
        "testData = censusTestData[['age', 'workType_cat', 'educationNumber', 'maritalStatus_cat', 'occupation_cat', 'relationship_cat', 'race_cat', 'sex_cat', 'gain', 'loss', 'hoursPerWeek', 'country_cat']]\n",
        "testTargets = censusTestData['income_cat']\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "workType\n",
            "education\n",
            "maritalStatus\n",
            "occupation\n",
            "relationship\n",
            "race\n",
            "sex\n",
            "country\n",
            "income\n",
            "age\n",
            "workType\n",
            "education\n",
            "maritalStatus\n",
            "occupation\n",
            "relationship\n",
            "race\n",
            "sex\n",
            "country\n",
            "income\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8ry3atVWW_1",
        "colab_type": "code",
        "outputId": "ba2f3fab-420e-4c30-f047-563cc0a0c3d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "print(trainData.dtypes)\n",
        "print(trainTargets.dtypes)\n",
        "print(testData.dtypes)\n",
        "print(testTargets.dtypes)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "age                  int64\n",
            "workType_cat          int8\n",
            "educationNumber      int64\n",
            "maritalStatus_cat     int8\n",
            "occupation_cat        int8\n",
            "relationship_cat      int8\n",
            "race_cat              int8\n",
            "sex_cat               int8\n",
            "gain                 int64\n",
            "loss                 int64\n",
            "hoursPerWeek         int64\n",
            "country_cat           int8\n",
            "dtype: object\n",
            "int8\n",
            "age                  category\n",
            "workType_cat             int8\n",
            "educationNumber       float64\n",
            "maritalStatus_cat        int8\n",
            "occupation_cat           int8\n",
            "relationship_cat         int8\n",
            "race_cat                 int8\n",
            "sex_cat                  int8\n",
            "gain                  float64\n",
            "loss                  float64\n",
            "hoursPerWeek          float64\n",
            "country_cat              int8\n",
            "dtype: object\n",
            "int8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6tTpp54ZlEg",
        "colab_type": "code",
        "outputId": "fac060f4-89b2-42cf-94b0-09f1add2c332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "trainData.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workType_cat</th>\n",
              "      <th>educationNumber</th>\n",
              "      <th>maritalStatus_cat</th>\n",
              "      <th>occupation_cat</th>\n",
              "      <th>relationship_cat</th>\n",
              "      <th>race_cat</th>\n",
              "      <th>sex_cat</th>\n",
              "      <th>gain</th>\n",
              "      <th>loss</th>\n",
              "      <th>hoursPerWeek</th>\n",
              "      <th>country_cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  workType_cat  educationNumber  ...  loss  hoursPerWeek  country_cat\n",
              "0   39             7               13  ...     0            40           39\n",
              "1   50             6               13  ...     0            13           39\n",
              "2   38             4                9  ...     0            40           39\n",
              "3   53             4                7  ...     0            40           39\n",
              "4   28             4               13  ...     0            40            5\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njBkkvEPdHGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainData = trainData.to_numpy()\n",
        "trainTargets = trainTargets.to_numpy()\n",
        "\n",
        "testData = testData.to_numpy()\n",
        "testTargets = testTargets.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo0ERJgJboH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(250, activation='relu', input_dim=12))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adamax', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWx7ct7ecbeI",
        "colab_type": "code",
        "outputId": "1cc0466c-1b0e-4624-fc66-9eaef6cdc187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "model.fit(trainData, trainTargets, epochs=20, batch_size=10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "32561/32561 [==============================] - 7s 227us/step - loss: 3.5588 - accuracy: 0.7923\n",
            "Epoch 2/20\n",
            "32561/32561 [==============================] - 7s 223us/step - loss: 2.1390 - accuracy: 0.8136\n",
            "Epoch 3/20\n",
            "32561/32561 [==============================] - 7s 220us/step - loss: 1.7687 - accuracy: 0.8199\n",
            "Epoch 4/20\n",
            "32561/32561 [==============================] - 7s 216us/step - loss: 1.4652 - accuracy: 0.8226\n",
            "Epoch 5/20\n",
            "32561/32561 [==============================] - 7s 214us/step - loss: 1.2433 - accuracy: 0.8262\n",
            "Epoch 6/20\n",
            "32561/32561 [==============================] - 7s 219us/step - loss: 0.9342 - accuracy: 0.8294\n",
            "Epoch 7/20\n",
            "32561/32561 [==============================] - 7s 218us/step - loss: 1.1448 - accuracy: 0.8297\n",
            "Epoch 8/20\n",
            "32561/32561 [==============================] - 7s 219us/step - loss: 0.8374 - accuracy: 0.8307\n",
            "Epoch 9/20\n",
            "32561/32561 [==============================] - 7s 216us/step - loss: 0.6931 - accuracy: 0.8349\n",
            "Epoch 10/20\n",
            "32561/32561 [==============================] - 7s 222us/step - loss: 0.6831 - accuracy: 0.8331\n",
            "Epoch 11/20\n",
            "32561/32561 [==============================] - 7s 221us/step - loss: 0.6923 - accuracy: 0.8319\n",
            "Epoch 12/20\n",
            "32561/32561 [==============================] - 7s 222us/step - loss: 0.5929 - accuracy: 0.8361\n",
            "Epoch 13/20\n",
            "32561/32561 [==============================] - 7s 218us/step - loss: 0.6114 - accuracy: 0.8363\n",
            "Epoch 14/20\n",
            "32561/32561 [==============================] - 7s 217us/step - loss: 0.6297 - accuracy: 0.8356\n",
            "Epoch 15/20\n",
            "32561/32561 [==============================] - 7s 219us/step - loss: 0.5245 - accuracy: 0.8362\n",
            "Epoch 16/20\n",
            "32561/32561 [==============================] - 7s 219us/step - loss: 0.4956 - accuracy: 0.8378\n",
            "Epoch 17/20\n",
            "32561/32561 [==============================] - 7s 217us/step - loss: 0.4373 - accuracy: 0.8393\n",
            "Epoch 18/20\n",
            "32561/32561 [==============================] - 7s 218us/step - loss: 0.4354 - accuracy: 0.8393\n",
            "Epoch 19/20\n",
            "32561/32561 [==============================] - 7s 221us/step - loss: 0.4476 - accuracy: 0.8381\n",
            "Epoch 20/20\n",
            "32561/32561 [==============================] - 7s 219us/step - loss: 0.4487 - accuracy: 0.8370\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f82fdfe9c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAYJ-G_kXG9v",
        "colab_type": "text"
      },
      "source": [
        "Third data set will be about heart diseases. based off of 14 features we will dertmine if an individual is sick. outputs are 0,1,2,3,4. 0 being sick 4 being very sick"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6bl_IDhXGkC",
        "colab_type": "code",
        "outputId": "979215d0-0fad-4675-daec-64831765b596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "header = [\"age\",\"sex\",\"cp\",\"trestbps\",\"chol\",\"fbs\",\"restecg\",\"thalach\",\"exang\",\"oldpeak\",\"slope\",\"ca\",\"thal\",\"num\"]\n",
        "\n",
        "heartData = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\", names=header, na_values=\"?\")\n",
        "\n",
        "heartData"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>233.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>286.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>67.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>45.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>264.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>68.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>57.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>57.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>236.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>38.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>303 rows Ã— 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age  sex   cp  trestbps   chol  ...  oldpeak  slope   ca  thal  num\n",
              "0    63.0  1.0  1.0     145.0  233.0  ...      2.3    3.0  0.0   6.0    0\n",
              "1    67.0  1.0  4.0     160.0  286.0  ...      1.5    2.0  3.0   3.0    2\n",
              "2    67.0  1.0  4.0     120.0  229.0  ...      2.6    2.0  2.0   7.0    1\n",
              "3    37.0  1.0  3.0     130.0  250.0  ...      3.5    3.0  0.0   3.0    0\n",
              "4    41.0  0.0  2.0     130.0  204.0  ...      1.4    1.0  0.0   3.0    0\n",
              "..    ...  ...  ...       ...    ...  ...      ...    ...  ...   ...  ...\n",
              "298  45.0  1.0  1.0     110.0  264.0  ...      1.2    2.0  0.0   7.0    1\n",
              "299  68.0  1.0  4.0     144.0  193.0  ...      3.4    2.0  2.0   7.0    2\n",
              "300  57.0  1.0  4.0     130.0  131.0  ...      1.2    2.0  1.0   7.0    3\n",
              "301  57.0  0.0  2.0     130.0  236.0  ...      0.0    2.0  1.0   3.0    1\n",
              "302  38.0  1.0  3.0     138.0  175.0  ...      0.0    1.0  NaN   3.0    0\n",
              "\n",
              "[303 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLD9t5FVdQIp",
        "colab_type": "code",
        "outputId": "22fa5b10-674c-4233-96e1-b1946b2d5ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "heartData.isna().any()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age         False\n",
              "sex         False\n",
              "cp          False\n",
              "trestbps    False\n",
              "chol        False\n",
              "fbs         False\n",
              "restecg     False\n",
              "thalach     False\n",
              "exang       False\n",
              "oldpeak     False\n",
              "slope       False\n",
              "ca           True\n",
              "thal         True\n",
              "num         False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgZxQh1XdRrV",
        "colab_type": "code",
        "outputId": "47b3e1b2-e747-4f23-8f1b-7c13a75ac077",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "heartData.dropna()\n",
        "heartData.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>233.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>286.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>67.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    age  sex   cp  trestbps   chol  fbs  ...  exang  oldpeak  slope   ca  thal  num\n",
              "0  63.0  1.0  1.0     145.0  233.0  1.0  ...    0.0      2.3    3.0  0.0   6.0    0\n",
              "1  67.0  1.0  4.0     160.0  286.0  0.0  ...    1.0      1.5    2.0  3.0   3.0    2\n",
              "2  67.0  1.0  4.0     120.0  229.0  0.0  ...    1.0      2.6    2.0  2.0   7.0    1\n",
              "3  37.0  1.0  3.0     130.0  250.0  0.0  ...    0.0      3.5    3.0  0.0   3.0    0\n",
              "4  41.0  0.0  2.0     130.0  204.0  0.0  ...    0.0      1.4    1.0  0.0   3.0    0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEveQyk0fy1v",
        "colab_type": "code",
        "outputId": "f25f9377-c57b-4766-aa5d-4fe55f0a49fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "features = heartData[[\"age\",\"sex\",\"cp\",\"trestbps\",\"chol\",\"fbs\",\"restecg\",\"thalach\",\"exang\",\"oldpeak\",\"slope\",\"ca\",\"thal\"]].to_numpy()\n",
        "targets = heartData['num'].to_numpy()\n",
        "\n",
        "for index in range(len(targets)):\n",
        "  if targets[index] > 0:\n",
        "    targets[index] = 1\n",
        "\n",
        "targets"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWBbvbTygOFD",
        "colab_type": "code",
        "outputId": "25b90eae-8e43-4a84-a1cc-4f62a6233542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "train_data, test_data, train_targets, test_targets = train_test_split(features, targets, test_size=.10)\n",
        "\n",
        "print (len(train_data))\n",
        "print(\"----------------\")\n",
        "print (len(train_targets))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "272\n",
            "----------------\n",
            "272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QjxZK7bg-4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del model\n",
        "model = Sequential()\n",
        "model.add(Dense(500, activation=\"relu\", input_dim=13))\n",
        "model.add(Dense(250, activation=\"relu\"))\n",
        "model.add(Dense(120, activation=\"relu\"))\n",
        "model.add(Dense(60, activation=\"relu\"))\n",
        "model.add(Dense(2, activation=\"softmax\"))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "che8ndrsh1FR",
        "colab_type": "code",
        "outputId": "a51b964f-0e52-41d4-d3ed-873b11f5dfa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_data, train_targets, epochs=50)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "272/272 [==============================] - 0s 458us/step - loss: 4.5420 - accuracy: 0.4706\n",
            "Epoch 2/50\n",
            "272/272 [==============================] - 0s 97us/step - loss: 0.6925 - accuracy: 0.5441\n",
            "Epoch 3/50\n",
            "272/272 [==============================] - 0s 100us/step - loss: 0.6920 - accuracy: 0.5441\n",
            "Epoch 4/50\n",
            "272/272 [==============================] - 0s 99us/step - loss: 0.6917 - accuracy: 0.5441\n",
            "Epoch 5/50\n",
            "272/272 [==============================] - 0s 115us/step - loss: 0.6912 - accuracy: 0.5441\n",
            "Epoch 6/50\n",
            "272/272 [==============================] - 0s 113us/step - loss: 0.6909 - accuracy: 0.5441\n",
            "Epoch 7/50\n",
            "272/272 [==============================] - 0s 109us/step - loss: 0.6905 - accuracy: 0.5441\n",
            "Epoch 8/50\n",
            "272/272 [==============================] - 0s 111us/step - loss: 0.6902 - accuracy: 0.5441\n",
            "Epoch 9/50\n",
            "272/272 [==============================] - 0s 131us/step - loss: 0.6899 - accuracy: 0.5441\n",
            "Epoch 10/50\n",
            "272/272 [==============================] - 0s 116us/step - loss: 0.6897 - accuracy: 0.5441\n",
            "Epoch 11/50\n",
            "272/272 [==============================] - 0s 98us/step - loss: 0.6895 - accuracy: 0.5441\n",
            "Epoch 12/50\n",
            "272/272 [==============================] - 0s 119us/step - loss: 0.6895 - accuracy: 0.5441\n",
            "Epoch 13/50\n",
            "272/272 [==============================] - 0s 122us/step - loss: 0.6893 - accuracy: 0.5441\n",
            "Epoch 14/50\n",
            "272/272 [==============================] - 0s 116us/step - loss: 0.6894 - accuracy: 0.5441\n",
            "Epoch 15/50\n",
            "272/272 [==============================] - 0s 116us/step - loss: 0.6894 - accuracy: 0.5441\n",
            "Epoch 16/50\n",
            "272/272 [==============================] - 0s 134us/step - loss: 0.6895 - accuracy: 0.5441\n",
            "Epoch 17/50\n",
            "272/272 [==============================] - 0s 105us/step - loss: 0.6893 - accuracy: 0.5441\n",
            "Epoch 18/50\n",
            "272/272 [==============================] - 0s 110us/step - loss: 0.6893 - accuracy: 0.5441\n",
            "Epoch 19/50\n",
            "272/272 [==============================] - 0s 113us/step - loss: 0.6893 - accuracy: 0.5441\n",
            "Epoch 20/50\n",
            "272/272 [==============================] - 0s 103us/step - loss: 0.6893 - accuracy: 0.5441\n",
            "Epoch 21/50\n",
            "272/272 [==============================] - 0s 104us/step - loss: 0.6894 - accuracy: 0.5441\n",
            "Epoch 22/50\n",
            "272/272 [==============================] - 0s 106us/step - loss: 0.6893 - accuracy: 0.5441\n",
            "Epoch 23/50\n",
            "272/272 [==============================] - 0s 107us/step - loss: 0.6893 - accuracy: 0.5441\n",
            "Epoch 24/50\n",
            "272/272 [==============================] - 0s 114us/step - loss: 0.6894 - accuracy: 0.5441\n",
            "Epoch 25/50\n",
            "272/272 [==============================] - 0s 127us/step - loss: 0.6904 - accuracy: 0.5441\n",
            "Epoch 26/50\n",
            "272/272 [==============================] - 0s 126us/step - loss: 0.6894 - accuracy: 0.5441\n",
            "Epoch 27/50\n",
            "272/272 [==============================] - 0s 111us/step - loss: 0.6894 - accuracy: 0.5441\n",
            "Epoch 28/50\n",
            "272/272 [==============================] - 0s 108us/step - loss: 0.6894 - accuracy: 0.5441\n",
            "Epoch 29/50\n",
            "272/272 [==============================] - 0s 107us/step - loss: 0.6894 - accuracy: 0.5441\n",
            "Epoch 30/50\n",
            "272/272 [==============================] - 0s 105us/step - loss: 0.6893 - accuracy: 0.5441\n",
            "Epoch 31/50\n",
            "272/272 [==============================] - 0s 114us/step - loss: 0.6894 - accuracy: 0.5441\n",
            "Epoch 32/50\n",
            "272/272 [==============================] - 0s 111us/step - loss: 0.6893 - accuracy: 0.5441\n",
            "Epoch 33/50\n",
            "272/272 [==============================] - 0s 108us/step - loss: 0.6895 - accuracy: 0.5441\n",
            "Epoch 34/50\n",
            "272/272 [==============================] - 0s 120us/step - loss: 0.6896 - accuracy: 0.5441\n",
            "Epoch 35/50\n",
            "272/272 [==============================] - 0s 110us/step - loss: 0.6893 - accuracy: 0.5441\n",
            "Epoch 36/50\n",
            "272/272 [==============================] - 0s 106us/step - loss: 0.6894 - accuracy: 0.5441\n",
            "Epoch 37/50\n",
            "272/272 [==============================] - 0s 118us/step - loss: 0.6894 - accuracy: 0.5441\n",
            "Epoch 38/50\n",
            "272/272 [==============================] - 0s 105us/step - loss: 0.6893 - accuracy: 0.5441\n",
            "Epoch 39/50\n",
            "272/272 [==============================] - 0s 127us/step - loss: 0.6896 - accuracy: 0.5441\n",
            "Epoch 40/50\n",
            "272/272 [==============================] - 0s 120us/step - loss: 0.6895 - accuracy: 0.5441\n",
            "Epoch 41/50\n",
            "272/272 [==============================] - 0s 120us/step - loss: 0.6894 - accuracy: 0.5441\n",
            "Epoch 42/50\n",
            "272/272 [==============================] - 0s 116us/step - loss: 0.6893 - accuracy: 0.5441\n",
            "Epoch 43/50\n",
            "272/272 [==============================] - 0s 163us/step - loss: 0.6894 - accuracy: 0.5441\n",
            "Epoch 44/50\n",
            "272/272 [==============================] - 0s 155us/step - loss: 0.6893 - accuracy: 0.5441\n",
            "Epoch 45/50\n",
            "272/272 [==============================] - 0s 118us/step - loss: 0.6894 - accuracy: 0.5441\n",
            "Epoch 46/50\n",
            "272/272 [==============================] - 0s 118us/step - loss: 0.6892 - accuracy: 0.5441\n",
            "Epoch 47/50\n",
            "272/272 [==============================] - 0s 108us/step - loss: 0.6892 - accuracy: 0.5441\n",
            "Epoch 48/50\n",
            "272/272 [==============================] - 0s 101us/step - loss: 0.6895 - accuracy: 0.5441\n",
            "Epoch 49/50\n",
            "272/272 [==============================] - 0s 101us/step - loss: 0.6895 - accuracy: 0.5441\n",
            "Epoch 50/50\n",
            "272/272 [==============================] - 0s 136us/step - loss: 0.6895 - accuracy: 0.5441\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f82fdefd7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqDy_xYUIuA2",
        "colab_type": "code",
        "outputId": "fb30131e-de28-4a71-a6d0-43427bf5c92c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "pred_train = model.predict(train_data)\n",
        "scores = model.evaluate(train_data, train_targets, verbose=0)\n",
        "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   \n",
        " \n",
        "pred_test = model.predict(test_data)\n",
        "scores2 = model.evaluate(test_data, test_targets, verbose=0)\n",
        "print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training data: 0.5441176295280457% \n",
            " Error on training data: 0.45588237047195435\n",
            "Accuracy on test data: 0.5161290168762207% \n",
            " Error on test data: 0.4838709831237793\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuEgqJ1yh7K-",
        "colab_type": "code",
        "outputId": "2753572b-c935-4355-953c-0008b7bb18c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "names = [\"mpg\", \"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model\", \"origin\", \"carname\"]\n",
        "carMPG = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\", header=None, names=names, na_values=[\"?\"], sep=\"\\s+\")\n",
        "\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "def replaceNaNAverage(data):\n",
        "  testColumn = data.isna().any()\n",
        "\n",
        "  # Loop through all isNa columns\n",
        "  for columnName, hasNaN in testColumn.items():\n",
        "      if hasNaN:\n",
        "          counts = Counter(data[columnName])\n",
        "          data[columnName] = data[columnName].fillna(counts.most_common(1)[0][0])\n",
        "  return data\n",
        "\n",
        "def normalizeData(data):\n",
        "  return (data - data.mean()) / (data.max() - data.min())\n",
        "\n",
        "carMPG = replaceNaNAverage(carMPG)\n",
        "\n",
        "print(carMPG)\n",
        "\n",
        "features = carMPG[['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model', 'origin']].to_numpy()\n",
        "targets = carMPG['mpg'].to_numpy()\n",
        "\n",
        "features = normalize(features, norm='l2')\n",
        "print(features)\n",
        "\n",
        "train_data, test_data, train_targets, test_targets = train_test_split(features, targets, test_size=.10)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      mpg  cylinders  displacement  ...  model  origin                    carname\n",
            "0    18.0          8         307.0  ...     70       1  chevrolet chevelle malibu\n",
            "1    15.0          8         350.0  ...     70       1          buick skylark 320\n",
            "2    18.0          8         318.0  ...     70       1         plymouth satellite\n",
            "3    16.0          8         304.0  ...     70       1              amc rebel sst\n",
            "4    17.0          8         302.0  ...     70       1                ford torino\n",
            "..    ...        ...           ...  ...    ...     ...                        ...\n",
            "393  27.0          4         140.0  ...     82       1            ford mustang gl\n",
            "394  44.0          4          97.0  ...     82       2                  vw pickup\n",
            "395  32.0          4         135.0  ...     82       1              dodge rampage\n",
            "396  28.0          4         120.0  ...     82       1                ford ranger\n",
            "397  31.0          4         119.0  ...     82       1                 chevy s-10\n",
            "\n",
            "[398 rows x 9 columns]\n",
            "[[0.00227237 0.08720228 0.03692605 ... 0.00340856 0.01988326 0.00028405]\n",
            " [0.00215407 0.09424049 0.04442766 ... 0.00309647 0.0188481  0.00026926]\n",
            " [0.0023157  0.09204908 0.04341938 ... 0.00318409 0.02026238 0.00028946]\n",
            " ...\n",
            " [0.00173762 0.05864478 0.03649009 ... 0.00503911 0.03562127 0.00043441]\n",
            " [0.00152075 0.04562258 0.03003487 ... 0.0070715  0.03117543 0.00038019]\n",
            " [0.00146781 0.04366744 0.03009017 ... 0.00711889 0.03009017 0.00036695]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIEsqajwKC2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(500, activation=\"relu\", input_dim=7))\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001), \n",
        "              loss='mae', \n",
        "              metrics=['mae', 'mse'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ9b0vOsLay2",
        "colab_type": "code",
        "outputId": "78f9b615-8922-4139-f420-a598ef94c814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_data, train_targets, epochs=150)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "358/358 [==============================] - 0s 111us/step - loss: 2.8045 - mae: 2.8045 - mse: 14.6274\n",
            "Epoch 2/150\n",
            "358/358 [==============================] - 0s 89us/step - loss: 2.9213 - mae: 2.9213 - mse: 16.5683\n",
            "Epoch 3/150\n",
            "358/358 [==============================] - 0s 85us/step - loss: 2.8272 - mae: 2.8272 - mse: 15.5111\n",
            "Epoch 4/150\n",
            "358/358 [==============================] - 0s 84us/step - loss: 2.8871 - mae: 2.8871 - mse: 16.0623\n",
            "Epoch 5/150\n",
            "358/358 [==============================] - 0s 85us/step - loss: 2.8599 - mae: 2.8599 - mse: 15.1981\n",
            "Epoch 6/150\n",
            "358/358 [==============================] - 0s 83us/step - loss: 3.0037 - mae: 3.0037 - mse: 16.0929\n",
            "Epoch 7/150\n",
            "358/358 [==============================] - 0s 84us/step - loss: 2.9405 - mae: 2.9405 - mse: 15.6718\n",
            "Epoch 8/150\n",
            "358/358 [==============================] - 0s 85us/step - loss: 2.8821 - mae: 2.8821 - mse: 15.9834\n",
            "Epoch 9/150\n",
            "358/358 [==============================] - 0s 83us/step - loss: 2.9419 - mae: 2.9419 - mse: 16.8176\n",
            "Epoch 10/150\n",
            "358/358 [==============================] - 0s 87us/step - loss: 2.7880 - mae: 2.7880 - mse: 15.0591\n",
            "Epoch 11/150\n",
            "358/358 [==============================] - 0s 88us/step - loss: 2.8982 - mae: 2.8982 - mse: 15.2166\n",
            "Epoch 12/150\n",
            "358/358 [==============================] - 0s 85us/step - loss: 2.8101 - mae: 2.8101 - mse: 15.2198\n",
            "Epoch 13/150\n",
            "358/358 [==============================] - 0s 86us/step - loss: 2.9756 - mae: 2.9756 - mse: 16.0530\n",
            "Epoch 14/150\n",
            "358/358 [==============================] - 0s 89us/step - loss: 2.8900 - mae: 2.8900 - mse: 15.9941\n",
            "Epoch 15/150\n",
            "358/358 [==============================] - 0s 91us/step - loss: 2.8213 - mae: 2.8213 - mse: 15.5822\n",
            "Epoch 16/150\n",
            "358/358 [==============================] - 0s 84us/step - loss: 2.7191 - mae: 2.7191 - mse: 14.3038\n",
            "Epoch 17/150\n",
            "358/358 [==============================] - 0s 83us/step - loss: 2.8687 - mae: 2.8687 - mse: 15.8954\n",
            "Epoch 18/150\n",
            "358/358 [==============================] - 0s 83us/step - loss: 2.8523 - mae: 2.8523 - mse: 14.7694\n",
            "Epoch 19/150\n",
            "358/358 [==============================] - 0s 83us/step - loss: 2.9514 - mae: 2.9514 - mse: 15.8201\n",
            "Epoch 20/150\n",
            "358/358 [==============================] - 0s 87us/step - loss: 3.0278 - mae: 3.0278 - mse: 16.2476\n",
            "Epoch 21/150\n",
            "358/358 [==============================] - 0s 81us/step - loss: 2.7379 - mae: 2.7379 - mse: 14.9928\n",
            "Epoch 22/150\n",
            "358/358 [==============================] - 0s 88us/step - loss: 2.8737 - mae: 2.8737 - mse: 15.7285\n",
            "Epoch 23/150\n",
            "358/358 [==============================] - 0s 115us/step - loss: 2.8603 - mae: 2.8603 - mse: 15.4946\n",
            "Epoch 24/150\n",
            "358/358 [==============================] - 0s 92us/step - loss: 2.8051 - mae: 2.8051 - mse: 15.0938\n",
            "Epoch 25/150\n",
            "358/358 [==============================] - 0s 82us/step - loss: 2.9195 - mae: 2.9195 - mse: 15.6222\n",
            "Epoch 26/150\n",
            "358/358 [==============================] - 0s 83us/step - loss: 2.9351 - mae: 2.9351 - mse: 15.8589\n",
            "Epoch 27/150\n",
            "358/358 [==============================] - 0s 82us/step - loss: 2.8670 - mae: 2.8670 - mse: 15.0509\n",
            "Epoch 28/150\n",
            "358/358 [==============================] - 0s 101us/step - loss: 2.7660 - mae: 2.7660 - mse: 14.5274\n",
            "Epoch 29/150\n",
            "358/358 [==============================] - 0s 81us/step - loss: 2.8639 - mae: 2.8639 - mse: 15.0521\n",
            "Epoch 30/150\n",
            "358/358 [==============================] - 0s 81us/step - loss: 2.9775 - mae: 2.9775 - mse: 16.2379\n",
            "Epoch 31/150\n",
            "358/358 [==============================] - 0s 89us/step - loss: 2.8350 - mae: 2.8350 - mse: 14.7240\n",
            "Epoch 32/150\n",
            "358/358 [==============================] - 0s 85us/step - loss: 2.7841 - mae: 2.7841 - mse: 14.5365\n",
            "Epoch 33/150\n",
            "358/358 [==============================] - 0s 82us/step - loss: 2.9500 - mae: 2.9500 - mse: 16.6743\n",
            "Epoch 34/150\n",
            "358/358 [==============================] - 0s 83us/step - loss: 2.9209 - mae: 2.9209 - mse: 15.7810\n",
            "Epoch 35/150\n",
            "358/358 [==============================] - 0s 86us/step - loss: 2.8462 - mae: 2.8462 - mse: 15.2408\n",
            "Epoch 36/150\n",
            "358/358 [==============================] - 0s 91us/step - loss: 2.9400 - mae: 2.9400 - mse: 15.4703\n",
            "Epoch 37/150\n",
            "358/358 [==============================] - 0s 89us/step - loss: 2.9415 - mae: 2.9415 - mse: 15.9535\n",
            "Epoch 38/150\n",
            "358/358 [==============================] - 0s 83us/step - loss: 2.7856 - mae: 2.7856 - mse: 14.8613\n",
            "Epoch 39/150\n",
            "358/358 [==============================] - 0s 85us/step - loss: 3.0428 - mae: 3.0428 - mse: 16.1338\n",
            "Epoch 40/150\n",
            "358/358 [==============================] - 0s 85us/step - loss: 2.8340 - mae: 2.8340 - mse: 14.9623\n",
            "Epoch 41/150\n",
            "358/358 [==============================] - 0s 82us/step - loss: 2.6728 - mae: 2.6728 - mse: 13.7819\n",
            "Epoch 42/150\n",
            "358/358 [==============================] - 0s 89us/step - loss: 2.8608 - mae: 2.8608 - mse: 15.2470\n",
            "Epoch 43/150\n",
            "358/358 [==============================] - 0s 89us/step - loss: 2.9096 - mae: 2.9096 - mse: 15.5641\n",
            "Epoch 44/150\n",
            "358/358 [==============================] - 0s 84us/step - loss: 2.7846 - mae: 2.7846 - mse: 14.8895\n",
            "Epoch 45/150\n",
            "358/358 [==============================] - 0s 83us/step - loss: 2.7501 - mae: 2.7501 - mse: 14.7659\n",
            "Epoch 46/150\n",
            "358/358 [==============================] - 0s 80us/step - loss: 2.9648 - mae: 2.9648 - mse: 15.8288\n",
            "Epoch 47/150\n",
            "358/358 [==============================] - 0s 89us/step - loss: 2.8712 - mae: 2.8712 - mse: 15.2690\n",
            "Epoch 48/150\n",
            "358/358 [==============================] - 0s 87us/step - loss: 3.0043 - mae: 3.0043 - mse: 16.4150\n",
            "Epoch 49/150\n",
            "358/358 [==============================] - 0s 87us/step - loss: 2.7280 - mae: 2.7280 - mse: 14.8487\n",
            "Epoch 50/150\n",
            "358/358 [==============================] - 0s 84us/step - loss: 2.7953 - mae: 2.7953 - mse: 14.6552\n",
            "Epoch 51/150\n",
            "358/358 [==============================] - 0s 83us/step - loss: 2.9731 - mae: 2.9731 - mse: 16.6512\n",
            "Epoch 52/150\n",
            "358/358 [==============================] - 0s 86us/step - loss: 2.8673 - mae: 2.8673 - mse: 15.5570\n",
            "Epoch 53/150\n",
            "358/358 [==============================] - 0s 116us/step - loss: 2.8432 - mae: 2.8432 - mse: 15.6766\n",
            "Epoch 54/150\n",
            "358/358 [==============================] - 0s 83us/step - loss: 2.7869 - mae: 2.7869 - mse: 14.8144\n",
            "Epoch 55/150\n",
            "358/358 [==============================] - 0s 87us/step - loss: 2.9364 - mae: 2.9364 - mse: 15.7771\n",
            "Epoch 56/150\n",
            "358/358 [==============================] - 0s 87us/step - loss: 2.7614 - mae: 2.7614 - mse: 15.3088\n",
            "Epoch 57/150\n",
            "358/358 [==============================] - 0s 105us/step - loss: 2.8433 - mae: 2.8433 - mse: 15.4525\n",
            "Epoch 58/150\n",
            "358/358 [==============================] - 0s 81us/step - loss: 2.7620 - mae: 2.7620 - mse: 14.5078\n",
            "Epoch 59/150\n",
            "358/358 [==============================] - 0s 82us/step - loss: 2.9512 - mae: 2.9512 - mse: 15.6454\n",
            "Epoch 60/150\n",
            "358/358 [==============================] - 0s 86us/step - loss: 2.8373 - mae: 2.8373 - mse: 15.2525\n",
            "Epoch 61/150\n",
            "358/358 [==============================] - 0s 84us/step - loss: 2.6939 - mae: 2.6939 - mse: 14.7726\n",
            "Epoch 62/150\n",
            "358/358 [==============================] - 0s 81us/step - loss: 3.0298 - mae: 3.0298 - mse: 16.4074\n",
            "Epoch 63/150\n",
            "358/358 [==============================] - 0s 81us/step - loss: 2.6515 - mae: 2.6515 - mse: 13.4007\n",
            "Epoch 64/150\n",
            "358/358 [==============================] - 0s 91us/step - loss: 2.9485 - mae: 2.9485 - mse: 15.7680\n",
            "Epoch 65/150\n",
            "358/358 [==============================] - 0s 85us/step - loss: 2.8731 - mae: 2.8731 - mse: 15.0432\n",
            "Epoch 66/150\n",
            "358/358 [==============================] - 0s 81us/step - loss: 2.8987 - mae: 2.8987 - mse: 15.6235\n",
            "Epoch 67/150\n",
            "358/358 [==============================] - 0s 87us/step - loss: 3.0315 - mae: 3.0315 - mse: 16.6246\n",
            "Epoch 68/150\n",
            "358/358 [==============================] - 0s 83us/step - loss: 2.6950 - mae: 2.6950 - mse: 14.3040\n",
            "Epoch 69/150\n",
            "358/358 [==============================] - 0s 82us/step - loss: 2.7741 - mae: 2.7741 - mse: 15.1008\n",
            "Epoch 70/150\n",
            "358/358 [==============================] - 0s 87us/step - loss: 2.7671 - mae: 2.7671 - mse: 14.7885\n",
            "Epoch 71/150\n",
            "358/358 [==============================] - 0s 87us/step - loss: 2.8175 - mae: 2.8175 - mse: 14.4316\n",
            "Epoch 72/150\n",
            "358/358 [==============================] - 0s 87us/step - loss: 2.9232 - mae: 2.9232 - mse: 15.8511\n",
            "Epoch 73/150\n",
            "358/358 [==============================] - 0s 88us/step - loss: 2.7099 - mae: 2.7099 - mse: 14.0467\n",
            "Epoch 74/150\n",
            "358/358 [==============================] - 0s 84us/step - loss: 2.7904 - mae: 2.7904 - mse: 15.4554\n",
            "Epoch 75/150\n",
            "358/358 [==============================] - 0s 85us/step - loss: 2.9785 - mae: 2.9785 - mse: 15.8231\n",
            "Epoch 76/150\n",
            "358/358 [==============================] - 0s 86us/step - loss: 2.7194 - mae: 2.7194 - mse: 14.6500\n",
            "Epoch 77/150\n",
            "358/358 [==============================] - 0s 102us/step - loss: 3.0351 - mae: 3.0351 - mse: 17.0095\n",
            "Epoch 78/150\n",
            "358/358 [==============================] - 0s 114us/step - loss: 2.8863 - mae: 2.8863 - mse: 15.4231\n",
            "Epoch 79/150\n",
            "358/358 [==============================] - 0s 83us/step - loss: 2.7631 - mae: 2.7631 - mse: 14.7806\n",
            "Epoch 80/150\n",
            "358/358 [==============================] - 0s 84us/step - loss: 2.8568 - mae: 2.8568 - mse: 15.0674\n",
            "Epoch 81/150\n",
            "358/358 [==============================] - 0s 82us/step - loss: 2.8762 - mae: 2.8762 - mse: 15.6974\n",
            "Epoch 82/150\n",
            "358/358 [==============================] - 0s 99us/step - loss: 2.8105 - mae: 2.8105 - mse: 14.9813\n",
            "Epoch 83/150\n",
            "358/358 [==============================] - 0s 95us/step - loss: 2.8665 - mae: 2.8665 - mse: 15.3642\n",
            "Epoch 84/150\n",
            "358/358 [==============================] - 0s 87us/step - loss: 3.0579 - mae: 3.0579 - mse: 16.5955\n",
            "Epoch 85/150\n",
            "358/358 [==============================] - 0s 84us/step - loss: 2.8671 - mae: 2.8671 - mse: 15.2807\n",
            "Epoch 86/150\n",
            "358/358 [==============================] - 0s 86us/step - loss: 2.8048 - mae: 2.8048 - mse: 15.8670\n",
            "Epoch 87/150\n",
            "358/358 [==============================] - 0s 97us/step - loss: 2.7542 - mae: 2.7542 - mse: 14.6676\n",
            "Epoch 88/150\n",
            "358/358 [==============================] - 0s 94us/step - loss: 2.8295 - mae: 2.8295 - mse: 14.3056\n",
            "Epoch 89/150\n",
            "358/358 [==============================] - 0s 86us/step - loss: 2.9311 - mae: 2.9311 - mse: 15.6583\n",
            "Epoch 90/150\n",
            "358/358 [==============================] - 0s 84us/step - loss: 2.7839 - mae: 2.7839 - mse: 15.0840\n",
            "Epoch 91/150\n",
            "358/358 [==============================] - 0s 101us/step - loss: 2.8462 - mae: 2.8462 - mse: 15.3346\n",
            "Epoch 92/150\n",
            "358/358 [==============================] - 0s 92us/step - loss: 2.9436 - mae: 2.9436 - mse: 16.2425\n",
            "Epoch 93/150\n",
            "358/358 [==============================] - 0s 91us/step - loss: 2.8717 - mae: 2.8717 - mse: 15.4494\n",
            "Epoch 94/150\n",
            "358/358 [==============================] - 0s 84us/step - loss: 2.6977 - mae: 2.6977 - mse: 14.2575\n",
            "Epoch 95/150\n",
            "358/358 [==============================] - 0s 87us/step - loss: 2.8404 - mae: 2.8404 - mse: 15.6156\n",
            "Epoch 96/150\n",
            "358/358 [==============================] - 0s 85us/step - loss: 2.8282 - mae: 2.8282 - mse: 14.8440\n",
            "Epoch 97/150\n",
            "358/358 [==============================] - 0s 86us/step - loss: 2.9198 - mae: 2.9198 - mse: 15.0628\n",
            "Epoch 98/150\n",
            "358/358 [==============================] - 0s 86us/step - loss: 2.6626 - mae: 2.6626 - mse: 14.0516\n",
            "Epoch 99/150\n",
            "358/358 [==============================] - 0s 85us/step - loss: 2.7319 - mae: 2.7319 - mse: 13.7786\n",
            "Epoch 100/150\n",
            "358/358 [==============================] - 0s 102us/step - loss: 2.9291 - mae: 2.9291 - mse: 14.9910\n",
            "Epoch 101/150\n",
            "358/358 [==============================] - 0s 86us/step - loss: 2.7632 - mae: 2.7632 - mse: 14.7427\n",
            "Epoch 102/150\n",
            "358/358 [==============================] - 0s 87us/step - loss: 2.7617 - mae: 2.7617 - mse: 14.8500\n",
            "Epoch 103/150\n",
            "358/358 [==============================] - 0s 85us/step - loss: 2.8295 - mae: 2.8295 - mse: 14.7429\n",
            "Epoch 104/150\n",
            "358/358 [==============================] - 0s 84us/step - loss: 2.8555 - mae: 2.8555 - mse: 15.5395\n",
            "Epoch 105/150\n",
            "358/358 [==============================] - 0s 85us/step - loss: 2.8772 - mae: 2.8772 - mse: 15.1967\n",
            "Epoch 106/150\n",
            "358/358 [==============================] - 0s 83us/step - loss: 2.9300 - mae: 2.9300 - mse: 15.8762\n",
            "Epoch 107/150\n",
            "358/358 [==============================] - 0s 83us/step - loss: 2.8596 - mae: 2.8596 - mse: 15.6443\n",
            "Epoch 108/150\n",
            "358/358 [==============================] - 0s 80us/step - loss: 2.8483 - mae: 2.8483 - mse: 15.7549\n",
            "Epoch 109/150\n",
            "358/358 [==============================] - 0s 98us/step - loss: 2.6902 - mae: 2.6902 - mse: 14.6839\n",
            "Epoch 110/150\n",
            "358/358 [==============================] - 0s 78us/step - loss: 2.9819 - mae: 2.9819 - mse: 17.9073\n",
            "Epoch 111/150\n",
            "358/358 [==============================] - 0s 81us/step - loss: 2.7984 - mae: 2.7984 - mse: 14.9258\n",
            "Epoch 112/150\n",
            "358/358 [==============================] - 0s 103us/step - loss: 2.9421 - mae: 2.9421 - mse: 16.3024\n",
            "Epoch 113/150\n",
            "358/358 [==============================] - 0s 89us/step - loss: 2.6845 - mae: 2.6845 - mse: 13.7937\n",
            "Epoch 114/150\n",
            "358/358 [==============================] - 0s 84us/step - loss: 2.9642 - mae: 2.9642 - mse: 16.8738\n",
            "Epoch 115/150\n",
            "358/358 [==============================] - 0s 86us/step - loss: 2.7476 - mae: 2.7476 - mse: 14.8679\n",
            "Epoch 116/150\n",
            "358/358 [==============================] - 0s 109us/step - loss: 2.8600 - mae: 2.8600 - mse: 15.4460\n",
            "Epoch 117/150\n",
            "358/358 [==============================] - 0s 84us/step - loss: 2.7901 - mae: 2.7901 - mse: 14.5988\n",
            "Epoch 118/150\n",
            "358/358 [==============================] - 0s 84us/step - loss: 2.8563 - mae: 2.8563 - mse: 15.5562\n",
            "Epoch 119/150\n",
            "358/358 [==============================] - 0s 84us/step - loss: 2.9447 - mae: 2.9447 - mse: 15.9323\n",
            "Epoch 120/150\n",
            "358/358 [==============================] - 0s 88us/step - loss: 2.8710 - mae: 2.8710 - mse: 15.3874\n",
            "Epoch 121/150\n",
            "358/358 [==============================] - 0s 92us/step - loss: 2.9120 - mae: 2.9120 - mse: 15.6100\n",
            "Epoch 122/150\n",
            "358/358 [==============================] - 0s 91us/step - loss: 2.6759 - mae: 2.6759 - mse: 13.7423\n",
            "Epoch 123/150\n",
            "358/358 [==============================] - 0s 89us/step - loss: 2.9472 - mae: 2.9472 - mse: 15.8762\n",
            "Epoch 124/150\n",
            "358/358 [==============================] - 0s 87us/step - loss: 2.7596 - mae: 2.7596 - mse: 14.7443\n",
            "Epoch 125/150\n",
            "358/358 [==============================] - 0s 85us/step - loss: 2.7834 - mae: 2.7834 - mse: 14.1981\n",
            "Epoch 126/150\n",
            "358/358 [==============================] - 0s 85us/step - loss: 2.6607 - mae: 2.6607 - mse: 13.7544\n",
            "Epoch 127/150\n",
            "358/358 [==============================] - 0s 84us/step - loss: 2.8757 - mae: 2.8757 - mse: 14.9877\n",
            "Epoch 128/150\n",
            "358/358 [==============================] - 0s 97us/step - loss: 2.7562 - mae: 2.7562 - mse: 14.6674\n",
            "Epoch 129/150\n",
            "358/358 [==============================] - 0s 87us/step - loss: 2.7436 - mae: 2.7436 - mse: 13.7071\n",
            "Epoch 130/150\n",
            "358/358 [==============================] - 0s 87us/step - loss: 2.7167 - mae: 2.7167 - mse: 14.3248\n",
            "Epoch 131/150\n",
            "358/358 [==============================] - 0s 81us/step - loss: 2.8385 - mae: 2.8385 - mse: 15.5018\n",
            "Epoch 132/150\n",
            "358/358 [==============================] - 0s 100us/step - loss: 2.7619 - mae: 2.7619 - mse: 14.7807\n",
            "Epoch 133/150\n",
            "358/358 [==============================] - 0s 83us/step - loss: 2.6943 - mae: 2.6943 - mse: 13.8272\n",
            "Epoch 134/150\n",
            "358/358 [==============================] - 0s 82us/step - loss: 2.8480 - mae: 2.8480 - mse: 15.2295\n",
            "Epoch 135/150\n",
            "358/358 [==============================] - 0s 85us/step - loss: 2.7826 - mae: 2.7826 - mse: 14.7368\n",
            "Epoch 136/150\n",
            "358/358 [==============================] - 0s 83us/step - loss: 2.7333 - mae: 2.7333 - mse: 14.4138\n",
            "Epoch 137/150\n",
            "358/358 [==============================] - 0s 82us/step - loss: 2.8308 - mae: 2.8308 - mse: 15.7424\n",
            "Epoch 138/150\n",
            "358/358 [==============================] - 0s 83us/step - loss: 2.8891 - mae: 2.8891 - mse: 15.3478\n",
            "Epoch 139/150\n",
            "358/358 [==============================] - 0s 98us/step - loss: 2.9754 - mae: 2.9754 - mse: 16.4346\n",
            "Epoch 140/150\n",
            "358/358 [==============================] - 0s 92us/step - loss: 2.6098 - mae: 2.6098 - mse: 13.2513\n",
            "Epoch 141/150\n",
            "358/358 [==============================] - 0s 109us/step - loss: 2.9847 - mae: 2.9847 - mse: 16.2181\n",
            "Epoch 142/150\n",
            "358/358 [==============================] - 0s 85us/step - loss: 2.8950 - mae: 2.8950 - mse: 15.6845\n",
            "Epoch 143/150\n",
            "358/358 [==============================] - 0s 105us/step - loss: 2.6721 - mae: 2.6721 - mse: 13.3717\n",
            "Epoch 144/150\n",
            "358/358 [==============================] - 0s 114us/step - loss: 2.9152 - mae: 2.9152 - mse: 15.6478\n",
            "Epoch 145/150\n",
            "358/358 [==============================] - 0s 88us/step - loss: 2.7878 - mae: 2.7878 - mse: 15.0381\n",
            "Epoch 146/150\n",
            "358/358 [==============================] - 0s 87us/step - loss: 2.8581 - mae: 2.8581 - mse: 15.3870\n",
            "Epoch 147/150\n",
            "358/358 [==============================] - 0s 86us/step - loss: 2.9399 - mae: 2.9399 - mse: 16.3094\n",
            "Epoch 148/150\n",
            "358/358 [==============================] - 0s 86us/step - loss: 2.7603 - mae: 2.7603 - mse: 14.6128\n",
            "Epoch 149/150\n",
            "358/358 [==============================] - 0s 85us/step - loss: 2.8793 - mae: 2.8793 - mse: 15.3482\n",
            "Epoch 150/150\n",
            "358/358 [==============================] - 0s 93us/step - loss: 2.7045 - mae: 2.7045 - mse: 13.6948\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f81f3d72748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvVqs4ilLfPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w0gvHjLQ-I7",
        "colab_type": "code",
        "outputId": "0ad93db6-3535-4d42-8932-ed64fc533fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import sklearn.metrics as sk\n",
        "\n",
        "# variance score\n",
        "print(\"Variance Score\")\n",
        "print(sk.explained_variance_score(test_targets, predictions))\n",
        "\n",
        "# max error\n",
        "from sklearn.metrics import max_error\n",
        "print(\"max error\")\n",
        "print(max_error(test_targets, predictions))\n",
        "\n",
        "# mean absolute error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "print(\"mean absolute error\")\n",
        "print(mean_absolute_error(test_targets, predictions))\n",
        "\n",
        "# Mean squared error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"mean squared error\")\n",
        "print(mean_squared_error(test_targets, predictions))\n",
        "\n",
        "\n",
        "# Mean squared log error\n",
        "print (\"mean squared log error\")\n",
        "print(sk.mean_squared_log_error(test_targets, predictions))\n",
        "\n",
        "# r2 score\n",
        "print (\"r2 score\")\n",
        "print (sk.r2_score(test_targets, predictions))"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Variance Score\n",
            "0.8464509966617164\n",
            "max error\n",
            "13.117713928222656\n",
            "mean absolute error\n",
            "4.9422805213928225\n",
            "mean squared error\n",
            "31.309842893030634\n",
            "mean squared log error\n",
            "0.06348962939319457\n",
            "r2 score\n",
            "0.38185875879477393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKnzXp4GN5yE",
        "colab_type": "text"
      },
      "source": [
        "With the first attempt I was able to get a variance score of 86% and a mean error of 2.02 r2 score 85%. I will use the car data set to try and get better predictions for miles per gallon.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Sigmoid function: Terrible horrible results... haha\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "tanh: No Better than sigmoid\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "selu: Better but not as good as relu\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "elu: Good but not as good as relu or selu\n",
        "\n",
        "---\n",
        "Decreasing the learning rate with the adam optimizer to .0001 increases results slightly but requires training for double the amount of iterations.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s06GMokyQjsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "error = test_targets - predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG-Wz5MQbyp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmKQ-diybzQg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "07c5015d-36d6-41f1-e581-50699d09e75e"
      },
      "source": [
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"prediction Error\")\n",
        "plt.ylabel(\"count\")"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'count')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmgBJxoLcNyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}